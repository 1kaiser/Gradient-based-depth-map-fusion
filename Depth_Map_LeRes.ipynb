{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLF9rkWtp1iNreVibJmXZW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/Gradient-based-depth-map-fusion/blob/main/Depth_Map_LeRes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs a conda environment and restarts the session"
      ],
      "metadata": {
        "id": "SRZGO6GgLggc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xbjnmy9Wd2mq",
        "outputId": "03fdd50e-29c3-4a73-c83b-dfc474ea56f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:27\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "exit() ## for restarting the session"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "connecting google drive link"
      ],
      "metadata": {
        "id": "BfTfAwxEJ2aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Gr3iJZ4qkJnQ",
        "outputId": "bd7aabd8-5483-4e85-c354-c0652b0fa67d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_folder = '/content/drive/MyDrive/OUT/data/machine_learning_test_dataset/DepthMap'\n",
        "import os\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "%cd {drive_folder}"
      ],
      "metadata": {
        "id": "OEDmpFn3nimL",
        "outputId": "758e9284-cc17-43de-8842-3c7da68374a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/OUT/data/machine_learning_test_dataset/DepthMap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        " \n",
        "# Read images with OpenCV.\n",
        "#images= None\n",
        "image_dir = str(drive_folder)+'/MEDIAPIPEinput/'\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "image_dir_out = str(drive_folder)+'/annotated_images'\n",
        "os.makedirs(image_dir_out, exist_ok=True)"
      ],
      "metadata": {
        "id": "IqbhO5UDFF8G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "video to franes"
      ],
      "metadata": {
        "id": "ZEIEmcdpkT5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_location = '/content/drive/MyDrive/OUT/data/machine_learning_test_dataset/test.mp4'\n",
        "\n",
        "frame_rate = 25\n",
        "!ffmpeg -y -hwaccel cuvid \\\n",
        "  -i {video_location} \\\n",
        "  -r {frame_rate} {image_dir}'out_%09d.png'"
      ],
      "metadata": {
        "id": "x-ucmeVYkWDa",
        "outputId": "5126bf21-39c4-4d22-8fb1-98f4342d335a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/OUT/data/machine_learning_test_dataset/test.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp42mp41iso4\n",
            "    creation_time   : 2021-12-09T21:02:50.000000Z\n",
            "  Duration: 00:00:40.58, start: 0.000000, bitrate: 673 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 1050x440, 601 kb/s, 25 fps, 25 tbr, 12800 tbn, 25600 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-12-09T21:02:50.000000Z\n",
            "      handler_name    : Vireo Eyes v2.7.3\n",
            "      encoder         : AVC Coding\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 65 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-12-09T21:02:50.000000Z\n",
            "      handler_name    : Vireo Ears v2.7.3\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/drive/MyDrive/OUT/data/machine_learning_test_dataset/DepthMap/MEDIAPIPEinput/out_%09d.png':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp42mp41iso4\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: png, rgb24, 1050x440, q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-12-09T21:02:50.000000Z\n",
            "      handler_name    : Vireo Eyes v2.7.3\n",
            "      encoder         : Lavc57.107.100 png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "clones the github repository >>> creates the conda environment >>> updates the environment with necessary libraryriies"
      ],
      "metadata": {
        "id": "2S4U7jiWL_xW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {drive_folder}\n",
        "!git clone https://github.com/1kaiser/Gradient-based-depth-map-fusion.git\n",
        "%cd Gradient-based-depth-map-fusion\n",
        "!conda create --name GBDF\n",
        "!conda activate GBDF\n",
        "!conda env update -f GBDF.yaml\n",
        "!python -m pip install opencv-python==4.6.0.66 torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!python -m pip install tqdm tensorboard setuptools==59.5.0 matplotlib scipy pip install timm==0.4.12 mmcv==0.6.2\n"
      ],
      "metadata": {
        "id": "emv7bnIpejU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Fusion Model checkpoints <<<"
      ],
      "metadata": {
        "id": "VFJ9MBGgMYb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = str(drive_folder)+'/Gradient-based-depth-map-fusion/models'\n",
        "import os\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "!wget https://github.com/1kaiser/Gradient-based-depth-map-fusion/releases/download/v0.1/model_dict.pt -O {model_dir}'/model_dict.pt'"
      ],
      "metadata": {
        "id": "JU5OIZAQgFap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Resnet Model >>> segmentation model selection Box { vertical-output: true, display-mode: \"form\" }\n",
        "model_selection = \"res101.pth\" #@param [\"res101.pth\", \"res50.pth\"] {allow-input: true}\n",
        "yolov5_model_path = 'LeRes/'+str(model_selection)\n",
        "!wget https://github.com/1kaiser/Gradient-based-depth-map-fusion/releases/download/v0.1/{model_selection} -O {yolov5_model_path}\n"
      ],
      "metadata": {
        "id": "xf8fofQyq9Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**running the python Script 📜 on input files in a folder**"
      ],
      "metadata": {
        "id": "YwY4TxQNMofv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {drive_folder}\n",
        "%cd Gradient-based-depth-map-fusion\n",
        "out_dir = image_dir_out\n",
        "!mkdir -p {out_dir}\n",
        "\n",
        "!python run.py \\\n",
        "-p LeRes101 \\\n",
        "-i {image_dir} \\\n",
        "-o {out_dir} \\\n",
        "-m 'models/model_dict.pt'"
      ],
      "metadata": {
        "id": "29Y5Syf9sBjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🖼️image frames to video🎥**"
      ],
      "metadata": {
        "id": "6OGkBWaakpsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "nNTWHDtMkvqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_rate = 25\n",
        "#create video 1\n",
        "!ffmpeg \\\n",
        "  -framerate {frame_rate} \\\n",
        "  -pattern_type glob \\\n",
        "  -i {image_dir}'/*.png' \\\n",
        "  inputA.mp4\n",
        "#create vodeo 2\n",
        "!ffmpeg \\\n",
        "  -framerate {frame_rate} \\\n",
        "  -pattern_type glob \\\n",
        "  -i {image_dir_out}'/*.png' \\\n",
        "  inputB.mp4\n",
        "#merge video 1 and video 2\n",
        "!ffmpeg \\\n",
        "  -i inputA.mp4 -i inputB.mp4 \\\n",
        "  -filter_complex \\\n",
        "  \"[0:v][1:v]vstack=inputs=2\" \\\n",
        "  finalOutput.mp4\n",
        "#add sound of main video to final output video\n",
        "!ffmpeg \\\n",
        "  -i 'finalOutput.mp4' -i {video_location} \\\n",
        "  -c:v copy -c:a copy -map 0:v:0 -map 1:a:0 \\\n",
        "  OUTPUT_FILE.mp4"
      ],
      "metadata": {
        "id": "QypBqFd-kskD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ffmpeg -ss 00:00:00 -t 5 -i '/content/OUTPUT_FILE.mp4' -filter_complex \"[0:v] palettegen\" palette.png\n",
        "# !ffmpeg -ss 00:00:00 -t 5 -i '/content/OUTPUT_FILE.mp4' -i palette.png -filter_complex \"[0:v] fps=10,scale=720:-1 [new];[new][1:v] paletteuse\" output.gif"
      ],
      "metadata": {
        "id": "Yo9eooOaEj63"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}