{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhEezpoacf4d/cgnYPa4/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/Gradient-based-depth-map-fusion/blob/main/Depth_Map_LeRes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs a conda environment and restarts the session"
      ],
      "metadata": {
        "id": "SRZGO6GgLggc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xbjnmy9Wd2mq"
      },
      "outputs": [],
      "source": [
        "!python -m pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "exit() ## for restarting the session"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "connecting google drive link"
      ],
      "metadata": {
        "id": "BfTfAwxEJ2aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Gr3iJZ4qkJnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_folder = '/content/drive/MyDrive/OUT/data/machine_learning_test_dataset/DepthMap'\n",
        "import os\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "%cd {drive_folder}"
      ],
      "metadata": {
        "id": "OEDmpFn3nimL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        " \n",
        "# Read images with OpenCV.\n",
        "#images= None\n",
        "image_dir = str(drive_folder)+'/MEDIAPIPEinput/'\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "image_dir_out = str(drive_folder)+'/annotated_images'\n",
        "os.makedirs(image_dir_out, exist_ok=True)"
      ],
      "metadata": {
        "id": "IqbhO5UDFF8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "video to franes"
      ],
      "metadata": {
        "id": "ZEIEmcdpkT5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_location = '/content/drive/MyDrive/OUT/data/machine_learning_test_dataset/test.mp4'\n"
      ],
      "metadata": {
        "id": "A62Hfv8hyQ_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "frame_rate = 25\n",
        "!ffmpeg -y -hwaccel cuvid \\\n",
        "  -i {video_location} \\\n",
        "  -r {frame_rate} {image_dir}'out_%09d.png'"
      ],
      "metadata": {
        "id": "x-ucmeVYkWDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "clones the github repository >>> creates the conda environment >>> updates the environment with necessary libraryriies"
      ],
      "metadata": {
        "id": "2S4U7jiWL_xW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {drive_folder}\n",
        "!git clone https://github.com/1kaiser/Gradient-based-depth-map-fusion.git\n",
        "%cd Gradient-based-depth-map-fusion\n",
        "!conda create --name GBDF\n",
        "!conda activate GBDF\n",
        "!conda env update -f GBDF.yaml\n",
        "!python -m pip install opencv-python==4.6.0.66 torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!python -m pip install tqdm tensorboard setuptools==59.5.0 matplotlib scipy pip install timm==0.4.12 mmcv==0.6.2\n"
      ],
      "metadata": {
        "id": "emv7bnIpejU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Fusion Model checkpoints <<<"
      ],
      "metadata": {
        "id": "VFJ9MBGgMYb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = str(drive_folder)+'/Gradient-based-depth-map-fusion/models'\n",
        "import os\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "!wget https://github.com/1kaiser/Gradient-based-depth-map-fusion/releases/download/v0.1/model_dict.pt -O {model_dir}'/model_dict.pt'"
      ],
      "metadata": {
        "id": "JU5OIZAQgFap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Resnet Model >>> segmentation model selection Box { vertical-output: true, display-mode: \"form\" }\n",
        "model_selection = \"res101.pth\" #@param [\"res101.pth\", \"res50.pth\"] {allow-input: true}\n",
        "yolov5_model_path = 'LeRes/'+str(model_selection)\n",
        "!wget https://github.com/1kaiser/Gradient-based-depth-map-fusion/releases/download/v0.1/{model_selection} -O {yolov5_model_path}\n"
      ],
      "metadata": {
        "id": "xf8fofQyq9Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**running the python Script üìú on input files in a folder**"
      ],
      "metadata": {
        "id": "YwY4TxQNMofv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {drive_folder}\n",
        "%cd Gradient-based-depth-map-fusion\n",
        "out_dir = image_dir_out\n",
        "!mkdir -p {out_dir}\n",
        "\n",
        "!python run.py \\\n",
        "-p LeRes101 \\\n",
        "-i {image_dir} \\\n",
        "-o {out_dir} \\\n",
        "-m 'models/model_dict.pt'"
      ],
      "metadata": {
        "id": "29Y5Syf9sBjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_000000001.png\n",
        "out_000000001.png"
      ],
      "metadata": {
        "id": "enY83__hh5pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "img_names = glob.glob(os.path.join(image_dir, \"*\"))\n",
        "img_names.sort()\n",
        "img_names\n",
        "\n",
        "out_img_names = glob.glob(os.path.join(out_dir, \"*\"))\n",
        "out_img_names.sort()\n",
        "out_img_names[2][-13:-4]\n",
        "out_img_names[2][-13:-4] in img_names\n",
        "g = []\n",
        "for i in range(len(img_names)):\n",
        "  g.append(img_names[i][-13:-4])\n",
        "g\n",
        "out_img_names[2][-13:-4] not in g\n"
      ],
      "metadata": {
        "id": "oPvjUsiDn0PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üñºÔ∏èimage frames to videoüé•**"
      ],
      "metadata": {
        "id": "6OGkBWaakpsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "nNTWHDtMkvqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_rate = 25\n",
        "#create video 1\n",
        "!ffmpeg \\\n",
        "  -framerate {frame_rate} \\\n",
        "  -pattern_type glob \\\n",
        "  -i {image_dir}'/*.png' \\\n",
        "  inputA.mp4\n",
        "#create vodeo 2\n",
        "!ffmpeg \\\n",
        "  -framerate {frame_rate} \\\n",
        "  -pattern_type glob \\\n",
        "  -i {image_dir_out}'/*.png' \\\n",
        "  inputB.mp4\n",
        "#merge video 1 and video 2\n",
        "!ffmpeg \\\n",
        "  -i inputA.mp4 -i inputB.mp4 \\\n",
        "  -filter_complex \\\n",
        "  \"[0:v][1:v]vstack=inputs=2\" \\\n",
        "  finalOutput.mp4\n",
        "#add sound of main video to final output video\n",
        "!ffmpeg \\\n",
        "  -i 'finalOutput.mp4' -i {video_location} \\\n",
        "  -c:v copy -c:a copy -map 0:v:0 -map 1:a:0 \\\n",
        "  OUTPUT_FILE.mp4"
      ],
      "metadata": {
        "id": "QypBqFd-kskD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ffmpeg -ss 00:00:00 -t 5 -i '/content/OUTPUT_FILE.mp4' -filter_complex \"[0:v] palettegen\" palette.png\n",
        "# !ffmpeg -ss 00:00:00 -t 5 -i '/content/OUTPUT_FILE.mp4' -i palette.png -filter_complex \"[0:v] fps=10,scale=720:-1 [new];[new][1:v] paletteuse\" output.gif"
      ],
      "metadata": {
        "id": "Yo9eooOaEj63"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}